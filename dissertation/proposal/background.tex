\section{Background and Related Work \label{background}}

\paragraph{Principles of composition and decomposition.}
A design process based on composition and decomposition tends to be effective when the model adheres to certain principles:
\begin{enumerate}
\item The model should define units of composition and a means of composition.
Obviously, a model that does not define a unit of composition and a means of composition cannot support a design process based on composition or decomposition.

\item The result of composition should either be a well-formed entity definable in the model or be undefined.
Thus, it is impossible to create an entity whose behavior and properties go beyond the scope of the model and therefore cannot be understood in terms of the model.
When the result of composition is defined, it should often (if not always) be a unit of composition.
This principle facilitates reuse and permits decomposition to an arbitrary \emph{degree}.

\item A unit of composition should be able to encapsulate other units of composition.
When this principle is combined with the previous principle, the result is \emph{recursive encapsulation} which permits decomposition to an arbitrary \emph{depth}.
Recursive encapsulation allows the system being designed to take on a hierarchical organization.

\item The behavior of a unit of composition should be encapsulated by its interface.
Encapsulation allows one to hide implementation details and is necessary for abstraction.

%% \item The model, unit of composition, and composition operator(s) should be defined so that composition can only reduce the set of possible behaviors that can be exhibited by a unit of composition.
%% That is, given a unit of composition with behavior set $B$ and an instance of composition resulting in a new behavior set $B'$, then it must be the case that $B' \subseteq B$.
%% Given that properties are assertions over behavior, this principle can be restated to say that composition can only restrict properties proved in isolation.
%% This principle facilitates reuse since the possible behaviors of a unit of composition is fixed.

\item Composition should be compositional meaning that the properties of a unit of composition can be stated in terms of the properties of its constituent units of composition.
Thus, when attempting to understand an entity resulting from composition, one need only examine its constituent parts and their interactions.
To illustrate, consider a system $X$ that is a pipeline formed by composing a filter system $F$ with reliable FIFO channel system $C$.
This principle states that the properties of the composed Filter-Channel $X$ can be expressed in terms of the properties of the Filter $F$ and Channel $C$.
%% The more interesting question is if the properties of $X$ can be systematically derived from $F$ and $C$ as this facilitates hierarchical reasoning.

\item Units of composition should have some notion of substitutional equivalence.
If a unit of composition $X$ contains a unit of composition $Y$, then a unit of composition $X'$ formed by substituting the definition of $Y$ into $X$ should be equivalent to $X$.
Substitutional equivalence guarantees that we can compose and decompose at will and summarizes the preceding principles.
We believe that substitution should be linear in the size of the units of composition.
To illustrate, suppose that $X$ and $Y$ are mathematical functions in the description above. %% and substitution, therefore, is equivalent to substituting function definitions.
%% Thus, if we take the size of a unit of composition to be the terms in a function, then $|X'| \approx |X| + |Y|$.
If we take the size of a unit of composition to be the number of terms in the definition of a function then $|X'| \approx |X| + |Y|$.
\end{enumerate}
A model adhering to these principles facilitates and supports \emph{principled composition and decomposition}.
Principled composition requires language support for interfaces, definitions, and substitutional equivalence.
A variety of useful domains including mathematical expressions, object-oriented programming, functional programming, and digital logic circuits support principled composition.

\paragraph{Reactive semantics.}
State (memory) is fundamental to reactive systems as past inputs influence future behavior.
Baeten concludes that the first step towards developing algebraic models for reactive systems was ``abandoning the idea that a program is a transformation from input to output, replacing this by an approach where all intermediate states are important\cite{baeten2005brief}.''
The state of a reactive system is often captured in program variables, e.g., Dijkstra's Cooperating Sequential Processes~\cite{dijkstra1965cooperating}, messages in a channel or queue, e.g.,  Milner's Calculus of Communicating Systems~\cite{milner1982calculus}, the Actor Model~\cite{agha1985actors}, or some combination of the two, e.g., Kahn Process Networks~\cite{kahn1974semantics}.
For generality, platforms typically allow complex state to be composed from primitive state, e.g., arrays, records, tuples, lists, sets, etc.

Computation in a reactive system then can be viewed as a sequence of state transitions~\cite{pnueli1981temporal}.
As these transitions may be complex, platforms typically allow complex state transitions to be composed from primitive state transitions.
Three orthogonal techniques for composing complex state transitions are expressions, sequential composition, and parallel composition.
\emph{Expressions} raise the level of abstraction by summarizing a computation whose intermediate results are unimportant.
A compiler or interpreter is free to schedule the evaluation of an expression in any way that preserves the semantics of the expression.
\emph{Sequential composition} is based on the idea that complex state transformations can be decomposed into a sequence of simpler state transformations.
\emph{Parallel composition} is based on the idea that complex state transformations can be composed by relating simpler state transformations, e.g., parallel assignment~\cite{barron1963main}.
Conceptually, the right-hand side (RHS) of a parallel assignment is computed before any of the variables on the left-hand side (LHS) are modified.

We distinguish between a \emph{reactive program} which is a static description of a set of transitions and a \emph{reactive process} which is the realization of the transitions of the corresponding reactive program.
State may be \emph{private} meaning that it may only be updated by a single reactive process or \emph{shared} meaning that it may be updated by multiple reactive processes.
The stack associated with a thread and thread specific storage are common examples of private state.
Shared state is often organized using object-oriented principles where updates to shared state are exposed in the form of structured transitions as opposed to raw assignment, e.g., a method to place a message in a queue.
Synchronization and communication are identified as a necessary activities in a reactive system~\cite{andrews1983concepts}.
The two approaches to communication are \emph{shared variables} and \emph{message passing}~\cite{andrews1983concepts}.

Multiple reactive processes can effect state transitions which may overlap in time, i.e., \emph{concurrency}.
Simultaneous state transitions, i.e., those that overlap in real time, require parallel physical resources.
State transitions that are formed by sequential composition may be overlapped by interleaving the primitive transitions of the corresponding complex transitions.
The result of concurrent state transitions that update the same (shared) state may be undefined.
Consequently, updates to shared state must be coordinated to prevent corruption.

Platforms for reactive systems, therefore, include the notion of \emph{atomicity} which says that certain transitions may not be interrupted, i.e., executed simultaneously or interleaved with another transition.
An \emph{event} is an atomic state transition.
\emph{Non-determinism} is another inherent attribute of reactive systems that conveys the idea that the order of events in a reactive system is not fixed.
Non-determinism is typically combined with atomicity to ensure that transitions are well-defined.
In a pair of events operating on the same state, for example, atomicity says that one event will be executed before the other while non-determinism says that the order in which they are executed is not determined.
True concurrency, i.e., simultaneity, is often modeled using a non-deterministic sequence of atomic events, e.g.,~\cite{nancy1996distributed}, \cite{chandy1989parallel}, \cite{manna1992temporal}.

As a sequence of atomic transitions, a reactive process (or rather the reactive program that defines it) may either have \emph{deterministic sequencing} or \emph{non-deterministic sequencing}.
As implied by the name, the order of transitions in a reactive process with deterministic sequencing is completely determined, i.e., there is always a single next transition (or termination).
The sequence of state transitions is called a \emph{flow of control}.
Reactive processes with deterministic sequencing are often based on an (infinite) loop that repeats for the duration of the reactive process.
Influential models based on deterministic sequencing include Dijkstra's Cooperating Sequential Processes~\cite{dijkstra1965cooperating} and Hoare's Communicating Sequential Processes~\cite{hoare1978communicating}.
Conversely, the order of transitions in a reactive process with non-deterministic sequencing is not completely determined, i.e., the next transition is selected from a set of candidates.
Platforms supporting reactive processes with non-deterministic sequencing include a \emph{scheduler} which chooses among the available transitions.
Reactive programs with deterministic sequencing correspond to a (circular) list of transitions while reactive programs with non-deterministic sequencing correspond to a set of transitions.
Deterministic sequencing and non-deterministic sequencing only describe individual reactive processes as the global choice for the next transition is in general non-deterministic.
Influential models based on non-deterministic sequencing include the UNITY model of Chandy and Misra~\cite{chandy1989parallel} and Lynch's I/O automata~\cite{nancy1996distributed}.

Atomicity may either be \emph{explicit} or \emph{implicit} in a model for reactive systems.
Platforms that support reactive processes with deterministic sequencing and shared variables typically include primitive transitions called \emph{synchronization primitives}, e.g., test-and-test, compare-and-swap, that may atomically update state and/or alter the flow of control~\cite{andrews1983concepts}.
Synchronization primitives can be used to construct more general synchronization mechanisms like semaphores and monitors~\cite{dijkstra1965cooperating}.
The goal of synchronization is to create atomic sequences of transitions called \emph{critical regions} or \emph{critical sections}~\cite{andrews1983concepts}.
Atomicity, therefore, is made explicit by the programmer.
%% Implicit atomicity uses language constructs, e.g., the \verb+synchronized+ keyword in Java, for synchronization.
Message passing combines communication with synchronization to achieve implicit atomicity in reactive programs based on deterministic sequencing~\cite{andrews1983concepts}.
Non-deterministic sequencing requires that all transitions be atomic and therefore implies implicit atomicity.

\paragraph{Related work.}
Reactive systems are designed and implemented using shared variables and/or message passing.
A popular approach to reactive systems is the pairing of shared variables with deterministic sequencing and explicit atomicity as is done in Dijkstra's Cooperating Sequential Processes~\cite{dijkstra1965cooperating}.
Andrews and Schneider describe a number of techniques associated with this approach including coroutines, fork/join, spin locks, semaphores, conditional critical regions, and monitors~\cite{andrews1983concepts}.
This model is supported by widely available platforms, i.e., operating systems, via processes with shared memory or threads~\cite{silberschatz2005operating}.
A number of design patterns have been developed based on this approach, e.g.,~\cite{schmidt2000pattern}, \cite{lea2000concurrent}.
As described by Lee~\cite{lee2006problem}, support for this model can be integrated into an existing sequential language through an external library, e.g., POSIX threads, or extensions to the base language, e.g., Cilk~\cite{blumofe1995cilk}, Split-C~\cite{culler1993parallel}, C++11~\cite{cxx11}.
Sutter and Larus~\cite{sutter2005software} and Lee~\cite{lee2006problem} provide a modern perspective on the difficulties associated with this approach.
In~\cite{sutter2005software}, the authors call for ``OO for concurrency--higher-level abstractions that help build concurrent programs, just as object-oriented abstractions help build large componentized programs.''
The proposed work is a step in this direction.

Atomic transactions have been proposed as an alternative to locks when synchronizing multiple processes.
The idea of an atomic transaction originated in the field of databases~\cite{Eswaran:1976:NCP:360363.360369}.
Knight~\cite{Knight:1986:AMF:319838.319854} and then Herlihy and Moss~\cite{Herlihy:1993:TMA:165123.165164} proposed cache-based hardware support for atomic transactions.
Hardware atomic transaction are forthcoming on modern processors~\cite{haswell}.
Software transactional memory, proposed by Shavit and Touitou~\cite{shavit1997software}, has sparked a great deal of interest and have been implemented in a number of languages, e.g., Clojure~\cite{halloway2009programming}.

Another popular approach to reactive systems is messaging passing with deterministic sequencing as is done in Hoare's Communicating Sequential Processes~\cite{hoare1978communicating}.
This model is also supported by widely available platforms via pipes, message queues, and sockets~\cite{silberschatz2005operating}.
A message passing channel may either be a fixed size or unbounded and accessed synchronously or asynchronously by either the sender or the receiver~\cite{andrews1983concepts}.
%% Synchronous sends block the sender until the channel is not full while asynchronous sends succeed or fail immediately.
%% Similarly, synchronous receives block the receiver until the channel is not empty while asynchronous receives succeed or fail immediately.
%% To illustrate, channels in CSP may contain one message and are accessed synchronously by both sender and receiver while channels in Kahn Process Networks~\cite{kahn1974semantics} are typically unbounded and accessed asynchronously by the sender and synchronously by the receiver.

Events, as proposed by Ousterhout~\cite{ousterhout1996threads}, and embodied in the Reactor and Proactor design patterns~\cite{schmidt2000pattern}, are a popular technique for structuring user applications based on deterministic sequencing.
The application is designed around a loop that multiplexes I/O events from the operating systems using a polling function like \verb+select+ or \verb+poll+.
In response to an I/O event, the application invokes an (atomic) event handler that may update the state of the process and perform non-blocking I/O on various channels.
Events invert the flow of control since high-level functions, e.g., processing a message, are triggered by low-level functions, e.g., receiving a byte.
The context of each computation must be managed explicitly which is referred to as ``stack ripping\cite{adya2002cooperative}.''
Event handlers from different logical computations may be interleaved giving the illusion of concurrency while avoiding the challenges of synchronization.
Event systems wishing to take advantage of true concurrency must use multiple event loops and face all of the challenges of multi-threaded programming.

Message passing may also be paired with non-deterministic sequencing.
In the asynchronous mode, the action of sending is distinct from receiving and requires a mail queue to buffer the unprocessed messages.
This is the approach taken in Hewitt's Actor model~\cite{hewitt1973universal} which is gaining popularity as exemplified by the Erlang programming language~\cite{armstrong1996concurrent}.
The proposed research will attempt to explore the synchronous mode where sending and receiving are combined in one atomic event which creates opportunities for synchronous composition.

%%The proposed work builds directly on existing work based on non-deterministic sequencing and complements the large body of work based on deterministic sequencing.
The UNITY model of Chandy and Misra~\cite{chandy1989parallel} and the I/O automata model of Lynch~\cite{nancy1996distributed} are two influential models for reactive systems based on non-deterministic sequencing.
These models are discussed in section~\ref{model}.
Of interest to the proposed work is the implementation of these models and their application to the design and development of reactive systems.
Granicz et al. propose a compilation method for UNITY in their Mojave compiler framework~\cite{GZH03}.
Other initiatives to implement the UNITY programming language are summarized in~\cite{GZH03}: 
\begin{quotation}
Few compilers have been developed for the UNITY language.
DeRoure's parallel implementation of UNITY~\cite{deroure1991parallel} compiles UNITY to a common backend language, BSP-occam; Huber's MasPar UNITY~\cite{huber1992maspar} compiles UNITY to MPL for execution on MasPar SIMD computers; and Radha and Muthukrishnan have developed a portable implementation of UNITY for Von Neumann machines~\cite{radha1993portable}\footnote{We believe all of these projects, including~\cite{GZH03}, are now defunct.}.
\end{quotation}
Goldman's Spectrum Simulation System~\cite{goldman1990distributed} allows one to simulate systems expressed as I/O automata.
The IOA toolkit is an implementation of I/O automata focused on verification and simulation~\cite{ioatoolkit}.
The IOA toolkit does contain a source-to-source compiler (IOA to Java) and a run-time that has been used to compile and execute distributed protocols~\cite{georgiou2009automated}.

%% Andrews and Schneider survey preliminary work in reactive systems which grew out of operating systems research and was concerned with reactive programs based on deterministic sequencing~\cite{andrews1983concepts}.
%% We argue that the ideas and techniques in \cite{andrews1983concepts}, e.g., coroutines, fork/join, spin locks, semaphores, conditional critical regions (condition variables), monitors (active objects, thread-safe interface), message passing, remote procedure call, atomic transactions (databases, software-transactional memory), are still representative of the state of the art in reactive systems.
%% Sutter and Larus~\cite{sutter2005software} and Lee~\cite{lee2006problem} provide a modern perspective on the difficulties associated with these techniques.
%% In~\cite{sutter2005software}, the authors call for ``OO for concurrency--higher-level abstractions that help build concurrent programs, just as object-oriented abstractions help build large componentized programs.''
%% The proposed work is a step in this direction.

%% Perhaps the first programs that were designed to run forever (and therefore are reactive) are the monitor programs (now called operating system kernels) of early multiprogramming systems, e.g., IBM STRETCH~\cite{codd1959multiprogramming}, and time-sharing or multitasking systems, e.g., Compatible Time-Sharing System~\cite{corbato1962experimental}.

%% Lee identifies four approaches to developing concurrent (reactive programs)~\cite{lee2006problem}.
%% One approach is to take an existing, presumably sequential, programming language and add support for concurrency via an external library, e.g., the POSIX threads library and the C programming language.
%% The advantage of this approach is that it is easily supported using standard compilers.
%% The disadvantage of this approach is the radical change in semantics.
%% Another approach is to extend an existing programming language with constructs for concurrency.
%% This solves the semantics problem but incurs the compiler problem as programmers are not inclined to use non-standard compilers.
%% A third approach is the creation of a new programming language, e.g., Erlang, Clojure, etc., based on different concurrency semantics.
%% Again, this solves the semantics problem but incurs all of the problems associated with the adoption of a new programming language.
%% The last approach is based on the use of a coordination language to coordinate the concurrent activities of various \emph{actors} which may be implemented in different languages.



%% The semantics of the library 

%% Split-C~\cite{culler1993parallel}
%% Cilk~\cite{blumofe1995cilk}


%% multicore


%% Preliminary work in reactive systems grew out operating systems research and was concerned with reactive programs based on deterministic sequencing~\cite{andrews1983concepts}.




%% Synchronization and communication are identified as necessary activities in concurrent programming while correct sequencing and interference are identified as the main challenges~\cite{andrews1983concepts}.
%% Shared variables (explicit synchronization) and message passing (implicit synchronization) are identified as two basic approaches to communication~\cite{andrews1983concepts}.



%% Andrews and Schneider provide a dated but relevant overview of this work~.

%% We provide a brief review of influential A complete discussion of all of the models and techniques for reactive systems based on deterministic sequencing is beyond the scope of this proposal.
%% While dated, 






%% An influential model based on shared variables is Dijkstra's Cooperating Sequential Processes which introduced the semaphore~\cite{dijkstra1965cooperating}.
%% An influential model based on message passing is Hoare's Communicating Sequential Processes which introduced the channel~\cite{hoare1978communicating}.



%% The two basic communication mechanisms are Communication The two basic techniques for structuring reactive p





%% A go




%% Solutions that separate synchronization and communication rely on synchronization primitives and shared variables for communication~\cite{andrews1983concepts}.
%% Solutions that combine synchronization and communication rely on message passing~\cite{andrews1983concepts}.
%% Dijkstra identifies the mutual exclusion problem of two processes and attributes an entirely software-based synchronization protocol to Dekker\cite{dijkstra1965cooperating}.
%% Dijkstra goes on to introduce the semaphore


%% The mutual exclusion problem was identified and software-based synchronization protocol is 



%% Indeed, the preliminary research in reactive systems grew out of operating system research.
















%% Major contributions include basic mutual exclusion with busy waiting and spin locks (Dekker's algorithm~), semaphores 

%% Important models in


%% Early work in reactive systems is concerned with 
%% Early work in reactive systems grew out of operating systems research and was concerned 

%% Modeling

%% Implementing


%% Perhaps the first reactive programs are the monitors (eventually operating systems) that grew out of the need to increase the utilization of early mainframes while providing for the interactive debugging of programs.
%% \emph{Multiprogrammed} systems such as the IBM STRETCH~\cite{codd1959multiprogramming} increased utilization by switching to another job when the current job was waiting on I/O.
%% \emph{Time sharing} or \emph{multitasking} systems such as the Compatible Time-Sharing System~\cite{corbato1962experimental} forces job switches at regular intervals prompting the development of interactive user programs.
%% The monitors for these systems are reactive programs as they were designed to run forever.
%% These developments led to the very influential MULTICS operating system~\cite{corbato1965introduction}.

%% The seminal paper on the theory of reactive systems is 







%% The first major development was the introduction of \emph{multiprogramming} where 

%% One such monitor, 
%% patrick1987general


%% execute (transformational) programs

%% (batch processing) and debug transformational programs.
%% Brooks provides an overview of this process~\cite{brooks1995mythical}.
%% The two major developments were the idea of \emph{multiprogramming} and \emph{time sharing}.


%% The low speeds of I/O equipment in early mainframes prompted programmers to debug their programs at the machine console.
%% The introduction of high-speed printers allowed the entire memory of the machine to be dumped when a program encountered an error.
%% A programmer could then 

%% ``on-machine debugging'' using a console in early mainframes.



%%  and increased leading to ``memory dumps'' where the entire memory of the machine would be dumped when an error was encounter and then analyzed by the programmer.
%% As memories grew larger it was not feasible to dump the entire memorybecame infeasible 


%% Thus, perhaps the first ``reactive systems'' were the interactive debugging consoles on early mainframes.



%% the progression of these systems




%% \paragraph{History.}
%% The general


%% The early days of computing resembled the transformation 

%% In the early days of computing, programmers would load a program, load its input

%% The earliest computers were operate

%% The earliest computers were designed to execute transformational programs.



%% Early computers were designed to run 

%% An early but clearly identifiable reactive system was a wind tunnel analysis program at the National Advisory Committee for Aeronautics' Lewis Flight Propulsion Laboratory~\cite{Mersel:1956:PIU:1455410.1455428}.
%% Wind tunnel experiments would interrupt batch jobs on a UNIVAC 1103A to provide a qick 

%% Baeten concludes that the first step towards developing models for reactive systems was ``abandoning the idea that a program is a transformation from input to output, replacing this by an approach where all intermediate states are important\cite{baeten2005brief}.''
%% The two dominant approaches to modeling reactive system are process algebras and state transition systems.
%% As implied by the name, the process algebra approach attempts to define laws of algebra or a calculus for specifying and reasoning about reactive systems~\cite{baeten2005brief}.
%% Influential process algebras include the Calculus of Communicating Systems~\cite{milner1982calculus} of Milner, Communicating Sequential Processes~\cite{hoare1978communicating} of Hoare, and the Algebra of Communicating Processes~\cite{bergstra1982fixed} of Berstra and Klop.
%% A typical formulation for a reactive system in a state transition systems such as the one presented by Manna and Pnueli in~\cite{manna1992temporal} characterizes a reactive system as a 4-tuple $(\Pi, \Sigma, T, \Theta)$ where $\Pi$ is ``a finite set of flexible \emph{state variables},'' $\Sigma$ is ``a set of states,'' $T$ is ``a finite set of transitions'', and $\Theta$ is ``an \emph{initial condition}.''
%% Equational reasoning, theorem proving, and model checking are three approaches used in the verification of reactive systems~\cite{baeten2005brief}.
%% We believe that state transition systems are a better foundation for a practical model for developing reactive systems since they seem to be grasped more readily when compared to typically more abstract process algebras.
%% The UNITY~\cite{chandy1989parallel} of Chandy and Misra and I/O automata~\cite{nancy1996distributed} of Lynch are two popular models for reactive systems based on state transition systems.
%% The proposed work builds on the system structuring techniques, i.e., decomposition and composition, of UNITY and I/O automata.

%% %% threads

%% %% actors

%% %% function call graphs
